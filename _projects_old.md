<!-- ---
layout: page
title: Projects
permalink: /projects/
--- -->

[Contact me](mailto:ebolotin6.git@gmail.com)

### Deep Learning
1. <a href="https://github.com/ebolotin6/kaggle-ml/tree/master/intel-image-classification_project" target="_blank"><strong>Classifying nature images with convolutional neural networks</strong></a> (Summer 2019)
	* **Dataset**: Intel image competition based dataset of 25k images labeled under 6 categories.
	* Purpose of this project is to classify images of nature into 6 distinct categories: buildings, forest, glacier, mountain, sea, and street. <a href="https://www.kaggle.com/puneet6060/intel-image-classification" target="_blank">Dataset</a> from an Intel-sponsored image classification competition.
	* **Packages/Tools used**: Keras, Tensorflow, and Kaggle for training on GPU

### Machine Learning
1. <a href="https://github.com/ebolotin6/DS740_portfolio/tree/master/final_project" target="_blank"><strong>Predicting whether it will rain tomorrow</strong></a> (Summer 2019)
	* **Dataset dimensions**: 142k observations x 23 predictors
	* Purpose of this project is predict whether it will rain tomorrow in Australia.
	* **ML methods used**: random forest, SVM, LDA (linear discriminant analysis), and a neural network. Recursive feature elimination with random forest used for subset selection.
<br /><br />
2. <a href="https://github.com/ebolotin6/DS740_portfolio/tree/master/midterm" target="_blank"><strong>Predicting retail price of vehicles</strong></a> (Summer 2019)
	* **Dataset dimensions**: 428 observations x 14 predictors
	* This project demonstrates the prediction of retail price using 7 regression modeling methods. 
	* **ML methods used**: random forest, bagging (bootstrap aggregation), boosting, multiple linear regression, shrinkage/regularization methods of Ridge, Lasso, and Elastic-Net regression, and K-nearest neighbors. regression subsets selection (regsubsets) used for model selection.

### Predictive Modeling
1. <a href="https://github.com/ebolotin6/loan_defaults" target="_blank"><strong>Predicting loan defaults with logistic regression</strong></a> (Spring 2019)
	* The goal of this project is to improve bank margins by optimizing loan-making decisions. This is accomplished by creating a logistic model that predicts whether loan applicants are likely to default on their loans. The dataset used to train this model includes 50,000 loans and 30 variables.
<br /><br />
2. <a href="https://github.com/ebolotin6/Fargo_Health_Group_Case/" target="_blank"><strong>Predicting health examinations</strong></a> (Fall 2018)
	* Analysis is based on a Harvard Business Review case titled "The Fargo Health Group (FHG) Case". The goal of the case is to create a predictive model to forecast medical examinations for a health organization. The purpose of this project is to solve the business case by: (1) demonstrating data imputation and (2) creating a predictive model using multiple time-series autoregressive forecasting methods.
	* **Methods used**: ARIMA and Holt's exponential smoothing.

### Hadoop / Big Data
1. The list below consists of projects that solve big data-related business questions using the Hadoop framework. Languages/software used: Pig, Hive, Spark, Scala, Zeppelin, Python, Java, AWS (EMR, S3, EC2, Athena, Glue). (Fall 2018)

	* **Final Project** -
		* **Part 1**: <a href="https://github.com/ebolotin6/hadoop_ds730/blob/master/Final_Project_Part_1.md" target="_blank"><strong>Big data analysis with Hive and Scala on Spark</strong></a>
		* **Part 2**: <a href="https://github.com/ebolotin6/hadoop_ds730/blob/master/Final_Project_Part_2.md" target="_blank"><strong>Parallel programming in Java: "Mailman's dilemma" algorithm</strong></a>. In part 2, I created an algorithm to solve for the most efficient way for a mailman to deliver mail, given N number of buildings.
		* **Part 3**: <a href="https://github.com/ebolotin6/hadoop_ds730/blob/master/Final_Project_Part_3.md" target="_blank"><strong>Big data on AWS: Flight analysis project</strong></a>. In part 3, I selected and hosted a big data set of flight arrival times data on AWS, and answered questions about this dataset using Scala.
	<br /><br />
	* **Other projects** - 
		* <a href="https://github.com/ebolotin6/hadoop_ds730/blob/master/Project_1_MapReduce.md" target="_blank"><strong>MapReduce and Python</strong></a>
		* <a href="https://github.com/ebolotin6/hadoop_ds730/blob/master/Project_2_Pig.md" target="_blank"><strong>Apache Pig</strong></a>
		* <a href="https://github.com/ebolotin6/hadoop_ds730/blob/master/Project_3_Hive.md" target="_blank"><strong>Apache Hive</strong></a>

### Natural Language Processing
1. <a href="https://github.com/ebolotin6/Twitter_Sentiment_Analysis/" target="_blank"><strong>Twitter Sentiment Analysis</strong></a> (Fall 2018)
	* The purpose of this project is to answer the question: are people that talk about fitness happier than people that talk about media (tv, movies, youtube, etc.)?
	* **Info**: Twitter data is collected using REST and Stream APIs, then cleaned, organized, and (sentiment) analyzed. Sentiment analysis is performed using Natural Language Toolkit VADER Sentiment Analysis. All of this is done in Python. Statistical analysis performed in R. 
	* **Other**: <a href="https://github.com/ebolotin6/Twitter_Sentiment_Analyzer/" target="_blank"><strong>Twitter Sentiment Analyzer</strong></a> is the standalone program created to perform sentiment analysis on Twitter data.

### Misc scripts, code
* Fall 2018 - **Data cleaning and analysis (Amazon Reviews)**: <a href="https://github.com/ebolotin6/UW_Assignments/blob/master/assignment_11/assignment11_python.ipynb" target="_blank">part 1: Python</a>, <a href="https://github.com/ebolotin6/UW_Assignments/blob/master/assignment_11/assignment11_R.pdf" target="_blank">part 2: R</a>
	* **Project purpose**: Analyze Amazon reviews to determine which characteristics make them most helpful.
	* **Project type**: Data cleaning, manipulation, and statistical analysis.
	* **Info**:	This project cleans and prepares data for statistical analysis (part 1), and then determines the characteristics of "helpful" vs "unhelpful" Amazon.com reviews (part 2).
<br /><br />
* Fall 2018 - <a href="https://github.com/ebolotin6/UW_Assignments/blob/master/assignment_8/Assignment_8_R.pdf" target="_blank"><strong>Hypothesis Testing</strong></a>
	* **Project purpose**: (a) To use statistical testing to determine the author of an anonymous essay - and - (b) to identify the language of encrypted text.
	* **Project type**: Statistical analysis (R)
	* **Info**: The goal of this project is to use hypothesis testing (T-Test and Chi-Squared Goodness of Fit in this case) to evaluate the truth of some claim (comparing sample vs population).
<br /><br />
* Fall 2018 - <a href="https://github.com/ebolotin6/UW_Assignments/blob/master/assignment_7/assignment7_python.ipynb" target="_blank"><strong>Text parsing & word counting</strong></a>
	* **Project purpose**: To perform statistics on arbitrary text using Python.
	* **Project type**: Data manipulation, analysis.
	* **Info**: The <a href="https://github.com/ebolotin6/UW_Assignments/blob/master/assignment_7/WordLength_Calc_v2.py" target="_blank">primary code</a> from this assignment was developed to analyze sentences from arbitrary text. It is an example of parsing and data analysis using Python.
<br /><br />
* Fall 2018 - **Data cleaning and analysis (College Rankings)**: <a href="https://github.com/ebolotin6/UW_Assignments/blob/master/assignment_9/assignment9_python.ipynb" target="_blank">part 1: Python</a>, <a href="https://github.com/ebolotin6/UW_Assignments/blob/master/assignment_9/assignment9_R.pdf" target="_blank">part 2: R</a>
	* **Project purpose**: To clean and analyze US News and World report College data.
	* **Project type**: Data cleaning and analysis in both Python and R.
	* **Info**: This is a two part project. In the first part, data is cleaned and prepared using Python. In the second part (this time in R), data is further cleaned and imputed, and then analyzed for significance.
<br /><br />

Copyright 2018 Eli Bolotin